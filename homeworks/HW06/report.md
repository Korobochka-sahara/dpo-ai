# HW06 – Report

> Файл: homeworks/HW06/report.md

## 1. Dataset

- Какой датасет выбран: S06-hw-dataset-04.csv
- Размер: 25000 строк, 62 столбца
- Целевая переменная: target (классы и их доли):
  - 0: 95.08%
  - 1: 4.92%
- Признаки: 60 числовых признаков (f01 – f60), столбец id используется как идентификатор, не как признак.

## 2. Protocol

- Разбиение: train/test = 0.8/0.2, random_state=42, стратификация по таргету y
- Подбор гиперпараметров: GridSearchCV на train, 5 фолдов, оптимизация по F1-score (для дисбалансного бинарного датасета важно улучшить качество предсказания редкого класса)
- Метрики:
  - accuracy – общая точность, чтобы видеть долю верных предсказаний
  - f1 – баланс precision и recall, особенно важно при дисбалансе классов
  - ROC-AUC – вероятность правильного ранжирования классов, удобная для бинарного дисбаланса

## 3. Models

Сравнивались следующие модели:

- DummyClassifier (baseline, стратегия most_frequent)
- LogisticRegression (через Pipeline с StandardScaler)
- DecisionTreeClassifier (подбирались max_depth, min_samples_leaf)
- RandomForestClassifier (подбирались max_depth, min_samples_leaf, max_features)
- GradientBoostingClassifier (подбирались n_estimators, learning_rate, max_depth)

Каждая модель обучалась на train, подбор параметров производился только на train, а оценка – один раз на test.

## 4. Results

Финальные метрики на test:

| Модель                  | Accuracy | F1     | ROC-AUC |
|-------------------------|---------|--------|---------|
| DummyClassifier         | 0.9508  | 0.0000 | 0.5000  |
| LogisticRegression      | 0.9632  | 0.4285 | 0.8339  |
| DecisionTreeClassifier  | 0.9676  | 0.5970 | 0.8283  |
| RandomForestClassifier  | 0.9738  | 0.6391 | 0.9019  |
| GradientBoosting        | 0.9748  | 0.7000 | 0.8905  |

Победитель: Gradient Boosting
- По согласованному критерию F1 + ROC-AUC
- Лучший баланс между точностью и полнотой, особенно для редкого класса 1

## 5. Analysis

- Устойчивость: при повторных 5 запусках RandomForest и GradientBoosting вариации метрик незначительны (<1% по F1), значит модели стабильны при смене random_state
- Ошибки: Confusion Matrix для Gradient Boosting (test):
4727 27
99   147
- Модель хорошо определяет класс 0 (TN=4727, FP=27)
- Основные ошибки приходятся на редкий класс 1 (FN=99, TP=147), что ожидаемо при сильном дисбалансе

- Интерпретация (Permutation Importance, top-15):
   feature  importance_mean  importance_std
     f58         0.134438        0.009685
     f25         0.120918        0.011347
     f53         0.108024        0.010117
     f54         0.094599        0.010490
     f47         0.088333        0.009386
     f13         0.059367        0.008252
     f33         0.055037        0.009931
     f38         0.047080        0.010912
     f11         0.030513        0.010392
     f08         0.029234        0.007222
     f41         0.027675        0.010375
     f04         0.026704        0.007611
     f27         0.025677        0.006122
     f43         0.022843        0.005713
     f16         0.010146        0.005617

Выводы: 
- Наиболее важные признаки (f58, f25, f53), оказывают наибольшее влияние на предсказание класса 1
- Согласуется с ожиданиями по данным: редкий класс определяется отдельными сильными сигналами в нескольких признаках
- Остальные признаки оказывают меньший эффект, что позволяет фильтровать шум

## 6. Conclusion

- Gradient Boosting показал лучший баланс между F1 и ROC-AUC на дисбалансном бинарном датасете
- Случайные леса и boosting стабильно работают, деревья менее чувствительны к шкалированию признаков
- Permutation importance помогает понять, на какие признаки модель опирается
- CV на train и использование отдельного test гарантируют честную оценку моделей
- DummyClassifier показывает, что дисбаланс сильно влияет на naive baseline
- Четкая структура артефактов (metrics, model, figures, meta) облегчает повторное использование и отчётность